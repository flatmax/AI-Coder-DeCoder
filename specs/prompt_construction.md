# Prompt Construction

This spec covers how system prompts, extra prompts, skill prompts, and
prompt snippets are loaded, assembled, and injected into LLM requests.

## Prompt Files

All prompt content lives under `config/prompts/`:

```
config/prompts/
‚îú‚îÄ‚îÄ system.md                  # Main system prompt
‚îú‚îÄ‚îÄ system_extra.md            # Optional extra instructions
‚îú‚îÄ‚îÄ prompt-snippets.json       # Quick-insert buttons for the UI
‚îî‚îÄ‚îÄ skills/
    ‚îî‚îÄ‚îÄ compaction.md          # Skill prompt for history compaction
```

## System Prompt

### Loading

`ac/prompts/loader.py` provides three functions:

```python
load_system_prompt() -> str        # Load config/prompts/system.md
load_extra_prompt() -> str | None  # Load config/prompts/system_extra.md
build_system_prompt() -> str       # Combine both
```

**`load_system_prompt()`** reads `config/prompts/system.md` from the
repository root. Raises `FileNotFoundError` if the file does not exist.

**`load_extra_prompt()`** reads `config/prompts/system_extra.md`. Returns
`None` if the file does not exist ‚Äî the extra prompt is optional.

**`build_system_prompt()`** concatenates the two:

```
<system.md content>

<system_extra.md content>     ‚Üê only if file exists
```

Separated by `\n\n`. This is the function called by all LLM request paths.

### Repository Root Resolution

The loader finds the repo root by walking up from `ac/prompts/loader.py`
(two parent directories). In PyInstaller bundles, it uses `sys._MEIPASS`
or `sys.executable` parent instead.

### Content

`system.md` contains the full agent instructions:

1. **Role** ‚Äî Expert coding agent with symbol map navigation.
2. **Symbol Map** ‚Äî How to read the map notation (`‚Üêrefs`, `i‚Üí` imports,
   kind prefixes). Rules for inherited methods, excluded files, requesting
   files.
3. **Edit Protocol** ‚Äî The EDIT/REPL block format with examples. Critical
   rules about no markdown fencing, exact matching, context in both
   sections, edit sizing, and sequential dependency merging.
4. **Workflow** ‚Äî Query ‚Üí Search Map ‚Üí Trace ‚Üí Request files ‚Üí Edit.
   Pre-edit checklist. Never-edit-unseen-files rule.
5. **Examples** ‚Äî Modify, insert, create, edit-with-backticks examples.
6. **Failure Recovery** ‚Äî Steps for retrying failed edits.

`system_extra.md` contains lightweight behavioral guidance:
- Request files before modifying them.
- Be lean but understandable.

## System Reminder

`ac/prompts/system_reminder.py` contains `SYSTEM_REMINDER`, a standalone
string with the EDIT/REPL format rules. This is a compact mechanical
reference for the edit block format ‚Äî shorter than the full system prompt's
edit protocol section.

```python
get_system_reminder(go_ahead_tip: str = "") -> str
```

Returns the reminder text, optionally appending a tip string. The reminder
is defined in Python code (not loaded from a file) for simplicity.

> **Note:** The system reminder is currently defined but not injected into
> streaming requests ‚Äî `_build_streaming_messages()` uses only
> `build_system_prompt()`. The reminder exists as infrastructure for
> potential mid-conversation reinforcement of edit format rules.

## Commit Message Prompt

`ac/llm/chat.py` defines `COMMIT_SYSTEM_PROMPT` as an inline Python string.
This is a separate system prompt used only for `get_commit_message()` calls:

- Role: Expert software engineer for git commit messages.
- Format: `<type>: <subject>\n\n<body>` with conventional commit types.
- Rules: Imperative mood, 50-char subject, 72-char body wrap.
- Output: Commit message only, no commentary.

This prompt is not assembled from files ‚Äî it is a constant in the chat
module. It does not use `build_system_prompt()` or any of the prompt
loading infrastructure.

## Skill Prompts

Skill prompts are markdown files under `config/prompts/skills/` loaded by
the subsystems that need them. Currently:

### compaction.md

Loaded by `TopicDetector._load_compaction_prompt()` using the same
repo-root resolution as the main prompt loader. Contains instructions for
the topic boundary detection LLM call ‚Äî see
[History Compaction](history_compaction.md).

Skill prompts are loaded lazily on first use and are independent of the
main system prompt pipeline.

## Message Assembly

The system prompt is injected into LLM messages by
`StreamingMixin._build_streaming_messages()`. The assembly flow:

```
build_system_prompt()
    ‚Üí system.md + system_extra.md

L0 block content:
    system_text                     ‚Üê from build_system_prompt()
    + REPO_MAP_HEADER + legend      ‚Üê symbol map legend (if present)
    + L0 symbol map entries         ‚Üê stable symbols
    + L0 files                      ‚Üê stable file contents
    + L0 history messages           ‚Üê stable conversation turns

‚Üí messages[0] = {role: "system", content: L0 block}
```

The system prompt is always the first content in the L0 cache block.
Subsequent tiers (L1‚ÄìL3, active) are user/assistant message pairs ‚Äî they
do not contain system prompt content.

See [Streaming Chat](streaming_chat.md) and
[Cache Management](cache_management.md) for the full message structure.

## Prompt Snippets

Prompt snippets are predefined messages shown as quick-insert buttons in
the webapp UI. They are not part of the LLM system prompt ‚Äî they are user
convenience features that insert text into the user's input field.

### File Format

`config/prompts/prompt-snippets.json`:

```json
{
  "snippets": [
    {
      "icon": "‚úÇÔ∏è",
      "tooltip": "Your last edit was truncated",
      "message": "Your last edit was truncated, please continue."
    }
  ]
}
```

| Field | Required | Description |
|-------|----------|-------------|
| `icon` | Yes | Emoji or character shown on the button |
| `tooltip` | No | Hover text. Falls back to first 50 chars of message. |
| `message` | Yes | Text inserted into the input field when clicked |

### Loading

`LiteLLM.get_prompt_snippets()` loads snippets with a two-location
fallback:

1. **Repo config**: `<repo_root>/config/prompts/prompt-snippets.json`
2. **Aicoder config**: `<aicoder_root>/config/prompts/prompt-snippets.json`

The repo-local file takes precedence, allowing per-project snippet
customization. Each snippet is validated to require at least `icon` and
`message` keys.

### Frontend Integration

`PromptView.loadPromptSnippets()` calls `get_prompt_snippets()` over JRPC
and stores the result. The snippet drawer UI renders each snippet as a
button. Clicking a snippet calls `PromptView.appendSnippet(message)` which
inserts the message text at the cursor position in the input textarea and
auto-resizes it.

The snippet drawer is toggled via a button in the input area and closes on
outside click or Escape keypress.

### Default Snippets

The bundled snippets cover common interaction patterns:

| Icon | Purpose |
|------|---------|
| ‚úÇÔ∏è | Continue a truncated edit |
| üîç | Remind AI to check its context |
| ‚úèÔ∏è | Correct malformed edit blocks |
| ‚è∏Ô∏è | Pause before implementation |
| ‚úÖ | Verify test coverage |
| üì¶ | Pre-commit checklist |
| üèÅ | Pre-commit with plan completion |

## Prompt Exports

`ac/prompts/__init__.py` exports:

```python
from .loader import load_system_prompt, load_extra_prompt, build_system_prompt

__all__ = ['load_system_prompt', 'load_extra_prompt', 'build_system_prompt']
```

`system_reminder.py` is not re-exported from the package ‚Äî it is imported
directly by consumers that need it.
